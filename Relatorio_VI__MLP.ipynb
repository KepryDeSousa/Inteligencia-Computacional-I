{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrlFi8bEb17AMMPDlkn/jF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KepryDeSousa/Inteligencia-Computacional-I/blob/main/Relatorio_VI__MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relatorio VI: *Redes Multicamadas*\n",
        "> Aluno : Jarom Kepri de Sousa M.\n",
        ">\n",
        "> Curso: Engenharia de Energias\n",
        "\n",
        "Desafio:\n",
        "> Implemente um sistema de controle para o motor CC com função de transferência da equação 18 do material anexo.\n",
        ">\n",
        ">através da estimação da função de transferência inversa da planta utilizando uma rede MLP.\n",
        ">\n",
        ">Defina os hiperparâmatros da rede, por tentativa e erro, deixando expresso quais o limites inferiores e superiores da faixa de variação escolhida pra essa busca, assim como o número de medições anteriores necessárias para se obter um bom resultado de modelagem.\n",
        "\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "VOXvmwZTtBGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Dados dos parâmetros do motor CC\n",
        "vi_max = 30.0  # Volts\n",
        "Ia_max = 2.0  # Amperes\n",
        "Ra = 3.0  # Ohms\n",
        "La = 6.0e-3  # Henries\n",
        "Ki = 50.0e-3  # Nm/A\n",
        "T_nominal = 0.1  # Newton-metro\n",
        "Jm = 40.0e-6  # Kg*m^2\n",
        "Bm = 40.0e-6  # Kg*m^2/s\n",
        "w_nominal = 300.0  # Radianos/s\n",
        "\n",
        "# Faixa de variação para os dados de entrada e saída\n",
        "vi_range = (0.0, vi_max)  # Volts\n",
        "Ia_range = (0.0, Ia_max)  # Amperes\n",
        "T_range = (0.0, T_nominal)  # Newton-metro\n",
        "w_range = (0.0, w_nominal)  # Radianos/s\n",
        "\n",
        "# Número de medições anteriores para obter um bom resultado de modelagem\n",
        "num_medicoes_anteriores = 10\n",
        "\n",
        "# Função para gerar dados de treinamento\n",
        "def gerar_dados_treinamento(num_samples):\n",
        "    vi = np.random.uniform(vi_range[0], vi_range[1], size=num_samples)\n",
        "    Ia = np.random.uniform(Ia_range[0], Ia_range[1], size=num_samples)\n",
        "    T = Ki * Ia\n",
        "    w = (T - Bm * w_nominal) / Jm\n",
        "    X = np.column_stack((vi, Ia))\n",
        "    y = np.column_stack((T, w))\n",
        "    return X, y\n",
        "\n",
        "# Hiperparâmetros da rede MLP\n",
        "num_epocas = 100\n",
        "tamanho_lote = 32\n",
        "taxa_aprendizado = 0.001\n",
        "num_neuronios_camada_oculta = 50\n",
        "\n",
        "# Criar a rede MLP\n",
        "modelo = Sequential()\n",
        "modelo.add(Dense(num_neuronios_camada_oculta, input_dim=2, activation='relu'))\n",
        "modelo.add(Dense(2, activation='linear'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Gerar dados de treinamento\n",
        "num_samples_treinamento = 1000\n",
        "X_treinamento, y_treinamento = gerar_dados_treinamento(num_samples_treinamento)\n",
        "\n",
        "# Treinar a rede MLP\n",
        "modelo.fit(X_treinamento, y_treinamento, epochs=num_epocas, batch_size=tamanho_lote, verbose=1)\n",
        "\n",
        "# Avaliar o desempenho da rede MLP\n",
        "num_samples_teste = 15\n",
        "X_teste, y_teste = gerar_dados_treinamento(num_samples_teste)\n",
        "score = modelo.evaluate(X_teste, y_teste, verbose=1)\n",
        "print(\"Loss: \", score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7PDbIT8L356",
        "outputId": "a02ad85e-e715-4ea7-892a-d49c82960958"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 2s 1ms/step - loss: 678926.2500\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 674209.1250\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 669409.5625\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 664206.7500\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 658148.3750\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 650770.6250\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 642117.4375\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 632305.3750\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 621429.7500\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 609482.8125\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 596153.5625\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 581837.5000\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 566755.3750\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 550895.1250\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 534519.9375\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 517587.8750\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 500720.6875\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 483324.6875\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 466644.9062\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 450114.1562\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 434606.8438\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 419773.7188\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 405961.7500\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 393477.7500\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 381746.4688\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 371515.6875\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 361978.4688\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 353774.5625\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 346259.8438\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 339836.7812\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 334645.5000\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 330161.3750\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 326308.6875\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 323276.1250\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 320358.1875\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 318181.9062\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 316338.5625\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 314793.2812\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 313464.4688\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 312273.1562\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 311268.9688\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 310152.5938\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 309164.3125\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 308243.7500\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 307233.1562\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 306302.1875\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 305334.5625\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 304383.4688\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 303423.3750\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 302423.8438\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 301394.6562\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 300354.0625\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 299346.0312\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 298258.6562\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 297159.9688\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 295991.7500\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 294874.7500\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 293645.0938\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 292464.8125\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 291278.8750\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 290034.0312\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 288863.1875\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 287581.6875\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 286240.3125\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 284889.6562\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 283598.2812\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 282238.9688\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 280863.9062\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 279422.5625\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 278047.6562\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 276726.1250\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 275228.0000\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 273693.6562\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 272239.6562\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 270821.1250\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 269142.5000\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 267712.4062\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 266034.7500\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 264469.0938\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 262893.5312\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 261262.4219\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 259687.2500\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 258013.9688\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 256486.0156\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 254716.8594\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 253025.4688\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 251376.7656\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 249589.4844\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 247863.5938\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 246126.2188\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 244311.4531\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 242583.8281\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 240722.4219\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 238909.8750\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 237131.8438\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 235254.6562\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 233448.3906\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 231643.6250\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 229724.9375\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 227924.4062\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 432501.2812\n",
            "Loss:  432501.28125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referencias:  \n",
        "> https://www.citisystems.com.br/motor-cc/\n",
        ">\n",
        ">https://iaexpert.academy/2018/05/17/deep-learning-redes-neurais-com-keras-e-python/\n",
        ">\n"
      ],
      "metadata": {
        "id": "qKvugCWpw3eb"
      }
    }
  ]
}